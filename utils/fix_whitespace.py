#!/usr/bin/env python3
"""
Whitespace cleanup script for Mercury source code repository.
Removes trailing whitespace and ensures single newline at end of text files.
Supports excluding specific files and directories from processing.
"""

import argparse
import difflib
import doctest
import os
import re
import stat
import sys
from pathlib import Path
from typing import Optional


# Third-party/imported library directories excluded by default
DEFAULT_EXCLUDED_EXTERNAL_DIRS = {
    'xsimd', 'rapidjson', 'lctrie',
}

# Autogenerated files to skip (basenames)
DEFAULT_EXCLUDED_AUTOGENERATED_FILES = {
    'configure', 'config.sub', 'config.guess', 'config.log', 'config.status',
    'aclocal.m4', 'compile', 'depcomp', 'install-sh', 'missing',
    'ltmain.sh', 'libtool',
}

# Directories excluded by default (binary content, build artifacts, etc.)
DEFAULT_EXCLUDED_DIRS = {
    '.git', '.svn', '.hg', '.bzr',
    '__pycache__', '.pytest_cache',
    'node_modules', 'venv', '.venv', 'env', '.env',
    '.tox', '.mypy_cache',
    'build', 'dist', '.build', '_build',
    'CMakeFiles', '.cmake',
    '.dSYM',  # macOS debug symbols
    'Debug', 'Release', 'RelWithDebInfo', 'MinSizeRel',
}

# File patterns excluded by default (binary files, build artifacts)
DEFAULT_EXCLUDED_PATTERNS = {
    # Compiled objects and libraries
    r'\.so(\.\d+)*$',      # Shared libraries
    r'\.a$',               # Static libraries
    r'\.o$',               # Object files
    r'\.obj$',             # Object files (Windows)
    r'\.exe$',             # Executables
    r'\.dll$', r'\.dylib$',  # Dynamic libraries

    # Archives and packages
    r'\.tar$', r'\.gz$', r'\.bz2$', r'\.xz$', r'\.tgz$',
    r'\.zip$', r'\.7z$',

    # Binary data files
    r'\.bin$', r'\.dat$', r'\.db$', r'\.sqlite$',
    r'\.pcap$', r'\.mcap$',  # Packet capture files
    r'\.sample$', r'\.pack$', r'\.idx$',  # Git and other binary formats

    # Python bytecode
    r'\.pyc$', r'\.pyo$', r'\.pkl$',

    # Images and media
    r'\.png$', r'\.jpg$', r'\.jpeg$', r'\.gif$', r'\.svg$',
    r'\.pdf$',

    # Test corpus files (often binary)
    r'/corpus/seed_\d+$',  # Fuzzing test corpus files
}

def is_binary_content(file_path: Path) -> bool:
    """
    Check if a file contains binary content by examining the entire file.
    This is the primary method for determining if a file is text or binary.
    Returns True if the file appears to be binary, False if it appears to be text.
    """
    try:
        with open(file_path, 'rb') as f:
            content = f.read()
            if not content:  # Empty file is considered text
                return False

            if b'\0' in content:  # Null bytes indicate binary (source files shouldn't have these)
                return True

            # Try to decode as UTF-8 (same encoding used by fix_whitespace)
            try:
                content.decode('utf-8')
                return False  # Successfully decoded, appears to be text
            except UnicodeDecodeError:
                return True  # Failed to decode as UTF-8, likely binary
    except (OSError, IOError):
        return True  # If we can't read it, treat as binary to be safe

def get_default_exclusion_reason(file_path: Path) -> str | None:
    """
    Determine if a file is excluded by default rules and return the reason.
    Returns None if the file should be processed.
    """
    # Exclude symlinks to avoid modifying files outside our control
    if file_path.is_symlink():
        return "symlink"

    # Exclude autogenerated files
    if file_path.name in DEFAULT_EXCLUDED_AUTOGENERATED_FILES:
        return "autogenerated"

    # Check if it matches any default exclusion patterns (saves time vs opening files)
    for pattern in DEFAULT_EXCLUDED_PATTERNS:
        if re.search(pattern, str(file_path), re.IGNORECASE):
            return "default excluded"

    # Check for binary content by attempting UTF-8 decode
    if is_binary_content(file_path):
        return "binary content"

    # If we get here, the file passed all exclusion checks and appears to be text
    return None  # Should be processed

def is_directory_excluded(dir_path: Path, user_exclusions: Optional[set[str]] = None) -> bool:
    """Check if a directory should be excluded from processing."""
    # Check default exclusions first
    if dir_path.name in DEFAULT_EXCLUDED_DIRS:
        return True

    # Check external library exclusions
    if dir_path.name in DEFAULT_EXCLUDED_EXTERNAL_DIRS:
        return True

    # Check user exclusions
    if user_exclusions and dir_path.name in user_exclusions:
        return True

    return False

def is_file_user_excluded(file_path: Path, user_exclusions: Optional[set[str]] = None) -> bool:
    """Check if a file should be excluded due to user-specified exclusions."""
    if not user_exclusions:
        return False

    # Check if the file name (basename) is in user exclusions
    if file_path.name in user_exclusions:
        return True

    # Check if any parent directory name is in user exclusions
    for parent in file_path.parents:
        if parent.name in user_exclusions:
            return True

    return False

def highlight_trailing_whitespace(line: str) -> str:
    """Highlight trailing whitespace with red background."""
    # ANSI color codes
    RED_BG = '\033[41m'  # Red background
    RESET = '\033[0m'    # Reset formatting

    # Find trailing whitespace (spaces and tabs, but not newlines)
    stripped = line.rstrip('\n\r')
    if stripped != stripped.rstrip(' \t'):
        # Has trailing whitespace
        content = stripped.rstrip(' \t')
        trailing = stripped[len(content):]
        newline = line[len(stripped):]
        return content + RED_BG + trailing + RESET + newline
    return line

def show_diff(file_path: Path, original: str, fixed: str) -> None:
    """Show a unified diff between original and fixed content with highlighted trailing whitespace."""
    # ANSI color codes
    RED = '\033[31m'     # Red text
    GREEN = '\033[32m'   # Green text
    RESET = '\033[0m'    # Reset formatting

    # Check for missing newline at end of original content
    original_missing_newline = original and not original.endswith('\n')

    original_lines = original.splitlines(keepends=True)
    fixed_lines = fixed.splitlines(keepends=True)

    diff = difflib.unified_diff(
        original_lines,
        fixed_lines,
        fromfile=f"a/{file_path.name}",
        tofile=f"b/{file_path.name}",
        lineterm=""
    )

    diff_lines = list(diff)
    if not diff_lines:
        return

    print(f"\nDiff for {file_path}:")

    for line in diff_lines:
        # Check if this is a diff header line (more specific than just startswith)
        is_diff_header = (line.startswith('--- ') and '/' in line) or (line.startswith('+++ ') and '/' in line)

        if line.startswith('-') and not is_diff_header:
            # Highlight trailing whitespace and color the entire removed line red
            highlighted_line = highlight_trailing_whitespace(line)
            if not line.endswith('\n'):
                # Line doesn't end with newline - show it and the indicator together
                print(RED + highlighted_line + RESET)
                print(RED + "\\ No newline at end of file" + RESET)
            else:
                print(RED + highlighted_line + RESET, end='')
        elif line.startswith('+') and not is_diff_header:
            # Color added lines green (they shouldn't have trailing whitespace)
            if not line.endswith('\n'):
                # Line doesn't end with newline
                print(GREEN + line + RESET)
            else:
                print(GREEN + line + RESET, end='')
        else:
            # Headers and context lines - no color
            if not line.endswith('\n'):
                print(line)
            else:
                print(line, end='')

    # Show newline addition indicator only once at the end if needed
    if original_missing_newline and fixed.endswith('\n'):
        print(GREEN + "\\ Newline added at end of file" + RESET)

def fix_whitespace(content: str) -> str:
    r"""
    Fix whitespace issues in text content.

    Removes trailing whitespace from each line, normalizes line endings to Unix style (\n),
    and ensures the content ends with exactly one newline (unless empty).

    Args:
        content: The text content to fix

    Returns:
        The fixed content as a string

    Examples:
        >>> fix_whitespace("")
        ''

        >>> fix_whitespace("  \n\n")
        '\n'

        >>> fix_whitespace("hello")
        'hello\n'

        >>> fix_whitespace("hello\n")
        'hello\n'

        >>> fix_whitespace("hello\r\n")
        'hello\n'

        >>> fix_whitespace("hello\r")
        'hello\n'

        >>> fix_whitespace("hello  \n")
        'hello\n'

        >>> fix_whitespace("hello\t\n")
        'hello\n'

        >>> fix_whitespace("line1  \r\nline2\t\nline3 \rline4   ")
        'line1\nline2\nline3\nline4\n'

        >>> fix_whitespace("\n\nhello\n\n")
        '\n\nhello\n'

        >>> fix_whitespace("hello\n\n\n")
        'hello\n'

        >>> fix_whitespace("  \n  \n")
        '\n'
    """
    # Remove trailing whitespace from each line
    lines = content.splitlines(keepends=True)
    fixed_lines = []

    for line in lines:
        # Remove trailing whitespace and normalize to Unix line endings (\n)
        if line.endswith(('\n', '\r')):
            fixed_line = line.rstrip() + '\n'
        else:
            fixed_line = line.rstrip()
        fixed_lines.append(fixed_line)

    # Join lines back together
    content = ''.join(fixed_lines)

    # Ensure file ends with exactly one newline (unless it's empty)
    if content and not content.endswith('\n'):
        content += '\n'
    elif content.endswith('\n\n'):
        # Remove extra newlines at the end
        content = content.rstrip('\n') + '\n'

    return content

def fix_whitespace_in_file(file_path: Path, dry_run: bool = False, verbose: bool = False) -> bool:
    """
    Fix whitespace issues in a file.
    Returns True if changes were made (or would be made in dry run).
    """
    try:
        # Read file content - fail on encoding errors to avoid corruption
        with open(file_path, 'r', encoding='utf-8') as f:
            original_content = f.read()
    except (OSError, IOError) as e:
        print(f"Error reading {file_path}: {e}")
        return False
    except UnicodeDecodeError as e:
        print(f"Unicode decode error in {file_path}: {e}")
        return False

    # Fix the whitespace using the core function
    fixed_content = fix_whitespace(original_content)

    # Check if changes were made
    if fixed_content == original_content:
        if verbose:
            print(f"OK (no changes needed): {file_path}")
        return False

    if verbose:
        show_diff(file_path, original_content, fixed_content)

    if dry_run:
        print(f"Would fix: {file_path}")
        return True

    # Write the fixed content back, preserving file permissions
    try:
        # Get original file permissions
        original_mode = file_path.stat().st_mode

        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(fixed_content)

        # Restore original permissions
        os.chmod(file_path, stat.S_IMODE(original_mode))

        print(f"Fixed: {file_path}")
        return True
    except (OSError, IOError) as e:
        print(f"Error writing {file_path}: {e}")
        return False

def get_files_to_process(root_path: Path, user_exclusions: Optional[set[str]] = None, verbose: bool = False) -> list[Path]:
    """
    Get a list of files to process from the given path.
    If root_path is a file, checks if it should be excluded before returning.
    If root_path is a directory, recursively finds all text files.
    """
    if root_path.is_file():
        # Check if file is excluded by user
        if is_file_user_excluded(root_path, user_exclusions):
            if verbose:
                print(f"IGNORED (user excluded): {root_path}")
            return []

        # Check if file is excluded by default rules
        exclusion_reason = get_default_exclusion_reason(root_path)
        if exclusion_reason:
            if verbose:
                print(f"IGNORED ({exclusion_reason}): {root_path}")
            return []

        return [root_path]

    if not root_path.is_dir():
        return []

    files_to_process = []

    for root, dirs, files in os.walk(root_path):
        root_path_current = Path(root)

        # Filter out excluded directories
        dirs[:] = [d for d in dirs if not is_directory_excluded(Path(d), user_exclusions)]

        for file in files:
            file_path = root_path_current / file

            # Check if file is excluded by user
            if is_file_user_excluded(file_path, user_exclusions):
                if verbose:
                    print(f"IGNORED (user excluded): {file_path}")
                continue

            # Check if file is excluded by default rules
            exclusion_reason = get_default_exclusion_reason(file_path)
            if exclusion_reason:
                if verbose:
                    print(f"IGNORED ({exclusion_reason}): {file_path}")
                continue

            files_to_process.append(file_path)

    return files_to_process

def main():
    parser = argparse.ArgumentParser(
        description="Remove trailing whitespace and ensure single newline at end of text files",
        epilog="""
examples:
  %(prog)s                              # Fix all files in current directory
  %(prog)s src/                         # Fix all files in src/ directory
  %(prog)s LICENSE README.md src/       # Fix multiple files and directories
  %(prog)s --dry-run                    # Preview changes without modifying files
  %(prog)s -v --dry-run                 # Show detailed diffs of changes
  %(prog)s --exclude build              # Add build directory to exclusions
  %(prog)s --exclude x --exclude .git   # Add file x and directory .git to exclusions

Default exclusions:
- Third-party libraries: xsimd, rapidjson, lctrie
- Autogenerated files: configure, config.*, aclocal.m4, etc.
- Binary files, build artifacts, and version control directories
""",
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    parser.add_argument(
        "paths",
        nargs="*",
        default=["."],
        help="Files or directories to process (default: current directory)"
    )
    parser.add_argument(
        "--exclude",
        metavar="ITEM",
        action="append",
        dest="excluded_items",
        help="Exclude a file or directory by name (in addition to default exclusions)"
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Show what would be changed without making changes"
    )
    parser.add_argument(
        "--verbose", "-v",
        action="store_true",
        help="Show verbose output with diffs"
    )
    parser.add_argument(
        "--test",
        action="store_true",
        help="Run doctests and exit"
    )

    args = parser.parse_args()

    # Run doctests if requested
    if args.test:
        print("Running doctests...")
        result = doctest.testmod(verbose=args.verbose)
        if result.failed == 0:
            print(f"All {result.attempted} doctests passed!")
            sys.exit(0)
        else:
            print(f"{result.failed} of {result.attempted} doctests failed")
            sys.exit(1)

    # Resolve all paths and check they exist
    root_paths = []
    for path_str in args.paths:
        root_path = Path(path_str).resolve()
        if not root_path.exists():
            print(f"Error: Path '{root_path}' does not exist")
            sys.exit(1)
        root_paths.append(root_path)

    # Build set of user exclusions (files and directories)
    user_exclusions = set()
    if args.excluded_items:
        # Add user-specified exclusions (normalize by removing trailing slashes)
        normalized_items = {item.rstrip('/') for item in args.excluded_items}
        user_exclusions.update(normalized_items)

    # Get list of files to process from all paths
    files_to_process = []
    for root_path in root_paths:
        files_from_path = get_files_to_process(root_path, user_exclusions, args.verbose)
        files_to_process.extend(files_from_path)

    if not files_to_process:
        paths_str = "', '".join(str(p) for p in root_paths)
        print(f"No text files found to process in '{paths_str}'")
        sys.exit(1)

    # Show processing information
    paths_str = "', '".join(str(p) for p in root_paths)
    print(f"Processing paths: '{paths_str}'")

    # Show exclusions info
    if user_exclusions:
        print(f"User exclusions: {', '.join(sorted(user_exclusions))}")
    print(f"Default excluded external libraries: {', '.join(sorted(DEFAULT_EXCLUDED_EXTERNAL_DIRS))}")
    print(f"Default excluded directories: {', '.join(sorted(DEFAULT_EXCLUDED_DIRS))}")
    print(f"Default excluded autogenerated files: {', '.join(sorted(DEFAULT_EXCLUDED_AUTOGENERATED_FILES))}")
    print(f"Default excluded patterns: {len(DEFAULT_EXCLUDED_PATTERNS)} patterns (binary files, archives, etc.)")

    if args.dry_run:
        print("\nDRY RUN MODE - No files will be modified")
    print()

    # Process all files
    files_changed = 0
    try:
        for file_path in files_to_process:
            if fix_whitespace_in_file(file_path, args.dry_run, args.verbose):
                files_changed += 1

        # Show results
        print()
        files_processed = len(files_to_process)

        print(f"Files scanned: {files_processed}")
        print(f"Files {'that would be ' if args.dry_run else ''}changed: {files_changed}")

        if files_changed > 0 and not args.dry_run:
            print("\nWhitespace cleanup completed!")
        elif files_changed > 0 and args.dry_run:
            print(f"\nRun without --dry-run to apply changes to {files_changed} files")
        else:
            print("\nNo whitespace issues found!")

    except KeyboardInterrupt:
        print("\nOperation cancelled by user")
        sys.exit(1)

if __name__ == "__main__":
    main()
